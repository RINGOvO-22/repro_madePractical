{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import cvxpy as cp\n",
    "import dccp\n",
    "import torch\n",
    "import numpy as np\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import zero_one_loss, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.patches as mpatches\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import os, psutil\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "XDIM = 2\n",
    "TRAIN_SLOPE = 1\n",
    "EVAL_SLOPE = 5\n",
    "COST = 1./XDIM\n",
    "X_LOWER_BOUND = -10\n",
    "X_UPPER_BOUND = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, percentage):\n",
    "    num_val = int(len(X)*percentage)\n",
    "    return X[num_val:], Y[num_val:], X[:num_val], Y[:num_val]\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    data = torch.cat((X, Y), 1)\n",
    "    data = data[torch.randperm(data.size()[0])]\n",
    "    X = data[:, :2]\n",
    "    Y = data[:, 2]\n",
    "    return X, Y\n",
    "\n",
    "def conf_mat(Y1, Y2):\n",
    "    num_of_samples = len(Y1)\n",
    "    mat = confusion_matrix(Y1, Y2, labels=[-1, 1])*100/num_of_samples\n",
    "    acc = np.trace(mat)\n",
    "    return mat, acc\n",
    "\n",
    "def calc_accuracy(Y, Ypred):\n",
    "    num = len(Y)\n",
    "    temp = Y - Ypred\n",
    "    acc = len(temp[temp == 0])*1./num\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_custom_normal_data(N, pos_mean, pos_std, neg_mean, neg_std):\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    pos_samples_num = N//2\n",
    "    neg_samples_num = N - pos_samples_num\n",
    "    posX = torch.randn((pos_samples_num, XDIM))*pos_std + pos_mean\n",
    "    negX = torch.randn((neg_samples_num, XDIM))*neg_std + neg_mean\n",
    "    \n",
    "    X = torch.cat((posX, negX), 0)\n",
    "    Y = torch.unsqueeze(torch.cat((torch.ones(len(posX)), -torch.ones(len(negX))), 0), 1)\n",
    "\n",
    "    X, Y = shuffle(X, Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCP classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCP:\n",
    "    def __init__(self, x_dim, funcs):\n",
    "        self.f_derivative = funcs[\"f_derivative\"]\n",
    "        self.g = funcs[\"g\"]\n",
    "        self.c = funcs[\"c\"]\n",
    "        \n",
    "        self.x = cp.Variable(x_dim)\n",
    "        self.xt = cp.Parameter(x_dim)\n",
    "        self.r = cp.Parameter(x_dim)\n",
    "        self.w = cp.Parameter(x_dim)\n",
    "        self.b = cp.Parameter(1)\n",
    "        self.slope = cp.Parameter(1)\n",
    "        self.v = cp.Parameter(x_dim)\n",
    "\n",
    "        target = self.x@self.f_derivative(self.xt, self.w, self.b, self.slope)-self.g(self.x, self.w, self.b, self.slope)-self.c(self.x, self.r, self.v)\n",
    "        constraints = [self.x >= X_LOWER_BOUND,\n",
    "                       self.x <= X_UPPER_BOUND]\n",
    "        self.prob = cp.Problem(cp.Maximize(target), constraints)\n",
    "        \n",
    "    def ccp(self, r):\n",
    "        \"\"\"\n",
    "        numpy to numpy\n",
    "        \"\"\"\n",
    "        self.xt.value = r\n",
    "        self.r.value = r\n",
    "        result = self.prob.solve()\n",
    "        diff = np.linalg.norm(self.xt.value - self.x.value)\n",
    "        cnt = 0\n",
    "        while diff > 0.0001 and cnt < 10:\n",
    "            cnt += 1\n",
    "            self.xt.value = self.x.value\n",
    "            result = self.prob.solve()\n",
    "            diff = np.linalg.norm(self.x.value - self.xt.value)\n",
    "        return self.x.value\n",
    "    \n",
    "    def optimize_X(self, X, w, b, slope, v):\n",
    "        \"\"\"\n",
    "        tensor to tensor\n",
    "        \"\"\"\n",
    "        w = w.detach().numpy()\n",
    "        b = b.detach().numpy()\n",
    "        v = v.detach().numpy()\n",
    "        slope = np.full(1, slope)\n",
    "        X = X.numpy()\n",
    "        \n",
    "        self.w.value = w\n",
    "        self.b.value = b\n",
    "        self.slope.value = slope\n",
    "        self.v.value = v\n",
    "        \n",
    "        return torch.stack([torch.from_numpy(self.ccp(x)) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DELTA():\n",
    "    \n",
    "    def __init__(self, x_dim, funcs):\n",
    "        self.g = funcs[\"g\"]\n",
    "        self.c = funcs[\"c_dpp_form\"]\n",
    "        \n",
    "        self.x = cp.Variable(x_dim)\n",
    "        self.w = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        self.b = cp.Parameter(1, value = np.random.randn(1))\n",
    "        self.v = cp.Parameter(x_dim, value = np.random.randn(x_dim), nonneg=True)\n",
    "        self.rv = cp.Parameter(x_dim, value = np.random.randn(x_dim)) # r times v\n",
    "        self.r2v = cp.Parameter(x_dim, value = np.random.randn(x_dim)) # r squared times v\n",
    "        self.f_der = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "\n",
    "        target = self.x@self.f_der-self.g(self.x, self.w, self.b, TRAIN_SLOPE)-self.c(self.x, self.v, self.rv, self.r2v)\n",
    "        constraints = [self.x >= X_LOWER_BOUND,\n",
    "                       self.x <= X_UPPER_BOUND]\n",
    "        objective = cp.Maximize(target)\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        self.layer = CvxpyLayer(problem, parameters=[self.w, self.b, self.v, self.rv, self.r2v, self.f_der],\n",
    "                                variables=[self.x])\n",
    "        \n",
    "    def optimize_X(self, X, w, b, v, F_DER):\n",
    "        rv = X*v\n",
    "        r2v = (X**2)*v\n",
    "        return self.layer(w, b, v, rv, r2v, F_DER)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gain & Cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x, w, b):\n",
    "    return x@w + b\n",
    "\n",
    "def f(x, w, b, slope):\n",
    "    return 0.5*cp.norm(cp.hstack([1, (slope*score(x, w, b) + 1)]), 2)\n",
    "\n",
    "def g(x, w, b, slope):\n",
    "    return 0.5*cp.norm(cp.hstack([1, (slope*score(x, w, b) - 1)]), 2)\n",
    "\n",
    "def c(x, r, v):\n",
    "    return COST*(((x-r)**2)@cp.abs(v))\n",
    "\n",
    "def c_dpp_form(x, v, rv, r2v):\n",
    "    return COST*cp.sum(cp.multiply(cp.square(x), v) - 2*cp.multiply(x, rv) + r2v)\n",
    "\n",
    "def f_derivative(x, w, b, slope):\n",
    "    return 0.5*cp.multiply(slope*((slope*score(x, w, b) + 1)/cp.sqrt((slope*score(x, w, b) + 1)**2 + 1)), w)\n",
    "\n",
    "funcs = {\"f\": f, \"g\": g, \"f_derivative\": f_derivative, \"c\": c, \"c_dpp_form\": c_dpp_form, \"score\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStrategicModel(torch.nn.Module):\n",
    "    def __init__(self, x_dim, funcs, train_slope, eval_slope, v_0, v_true, strategic=False, robust=False):\n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "    \n",
    "        super(MyStrategicModel, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.train_slope, self.eval_slope = train_slope, eval_slope\n",
    "        self.strategic = strategic\n",
    "        self.robust = robust\n",
    "        \n",
    "        self.w = torch.nn.parameter.Parameter(math.sqrt(1/x_dim)*(1-2*torch.rand(x_dim, dtype=torch.float64, requires_grad=True)))\n",
    "        self.b = torch.nn.parameter.Parameter(torch.rand(1, dtype=torch.float64, requires_grad=True))\n",
    "        self.v_true = v_true\n",
    "        self.v_0 = v_0\n",
    "        if self.robust:\n",
    "            self.V = torch.stack([self.v_0 + 1.7, self.v_0 - 1.7])\n",
    "        else:\n",
    "            self.V = torch.stack([self.v_0])\n",
    "        \n",
    "        self.ccp = CCP(x_dim, funcs)\n",
    "        self.delta = DELTA(x_dim, funcs)\n",
    "        \n",
    "    def forward(self, X, evaluation=False):\n",
    "        outputs = torch.zeros((self.V.size()[0], X.size()[0]))\n",
    "        for i, v in enumerate(self.V):\n",
    "            if self.strategic:\n",
    "                if evaluation:\n",
    "                    XT = self.ccp.optimize_X(X, self.w, self.b, self.eval_slope, torch.abs(v))\n",
    "                    X_opt = XT\n",
    "                else:\n",
    "                    XT = self.ccp.optimize_X(X, self.w, self.b, self.train_slope, torch.abs(v))\n",
    "                    F_DER = self.get_f_ders(XT, self.train_slope)\n",
    "                    X_opt = self.delta.optimize_X(X, self.w, self.b, torch.abs(v), F_DER) # Xopt should equal to XT but we do it again for the gradients\n",
    "                output = self.score(X_opt)\n",
    "            else:\n",
    "                output = self.score(X) \n",
    "            outputs[i] = output\n",
    "        return outputs\n",
    "    \n",
    "    def optimize_X(self, X):\n",
    "        return self.ccp.optimize_X(X, self.w, self.b, self.eval_slope, self.v_true)\n",
    "    \n",
    "    def score(self, x):\n",
    "        return x@self.w + self.b\n",
    "    \n",
    "    def get_f_ders(self, XT, slope):\n",
    "        return torch.stack([0.5*slope*((slope*self.score(xt) + 1)/torch.sqrt((slope*self.score(xt) + 1)**2 + 1))*self.w for xt in XT])\n",
    "\n",
    "    def calc_accuracy(self, Y, Y_pred):\n",
    "        Y_pred = torch.sign(torch.mean(torch.sign(Y_pred), 0))\n",
    "        Y_pred[Y_pred == 0] = -Y[Y_pred == 0]\n",
    "        num = len(Y)\n",
    "        temp = Y - Y_pred\n",
    "        acc = len(temp[temp == 0])*1./num        \n",
    "        return acc\n",
    "    \n",
    "    def evaluate(self, X, Y):      \n",
    "        return self.calc_accuracy(Y, self.forward(X, evaluation=True))\n",
    "    \n",
    "    def loss(self, Y, Y_pred):\n",
    "        return torch.max(torch.mean(torch.clamp(1 - Y_pred * Y, min=0), 1))\n",
    "    \n",
    "    def save_model(self, train_errors, val_errors, train_losses, val_losses, info, path, comment=None):\n",
    "        if comment is not None:\n",
    "            path += \"/\" + comment\n",
    "            \n",
    "        filename = path + \"/model.pt\"\n",
    "        if not os.path.exists(os.path.dirname(filename)):\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        \n",
    "        pd.DataFrame(self.V.detach().numpy()).to_csv(path + '/V.csv')\n",
    "        pd.DataFrame(self.v_0.detach().numpy()).to_csv(path + '/v_0.csv')\n",
    "        pd.DataFrame(self.v_true.detach().numpy()).to_csv(path + '/v_true.csv')\n",
    "        \n",
    "        pd.DataFrame(np.array(train_errors)).to_csv(path + '/train_errors.csv')\n",
    "        pd.DataFrame(np.array(val_errors)).to_csv(path + '/val_errors.csv')\n",
    "        pd.DataFrame(np.array(train_losses)).to_csv(path + '/train_losses.csv')\n",
    "        pd.DataFrame(np.array(val_losses)).to_csv(path + '/val_losses.csv')\n",
    "        \n",
    "        with open(path + \"/info.txt\", \"w\") as f:\n",
    "            f.write(info)\n",
    "    \n",
    "    def load_model(self, filename):\n",
    "        self.load_state_dict(torch.load(filename))\n",
    "        self.eval()\n",
    "    \n",
    "    def fit(self, path, X, Y, Xval, Yval, opt, opt_kwargs={\"lr\":1e-3}, batch_size=128, epochs=100, verbose=False, callback=None, comment=None):\n",
    "        train_dset = TensorDataset(X, Y)\n",
    "        train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "        opt = opt(self.parameters(), **opt_kwargs)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_errors = []\n",
    "        val_errors = []\n",
    "        \n",
    "        best_val_error = 1\n",
    "        consecutive_no_improvement = 0\n",
    "\n",
    "        total_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            t1 = time.time()\n",
    "            batch = 1\n",
    "            train_losses.append([])\n",
    "            train_errors.append([])\n",
    "            for Xbatch, Ybatch in train_loader:\n",
    "#                 try:\n",
    "                opt.zero_grad()\n",
    "                Ybatch_pred = self.forward(Xbatch)\n",
    "                l = self.loss(Ybatch, Ybatch_pred)\n",
    "                l.backward()\n",
    "                opt.step()\n",
    "                train_losses[-1].append(l.item())\n",
    "                with torch.no_grad():\n",
    "                    e = self.calc_accuracy(Ybatch, Ybatch_pred)\n",
    "                    train_errors[-1].append(1-e)\n",
    "                if verbose:\n",
    "                    print(\"batch %03d / %03d | loss: %3.5f | err: %3.5f\" %\n",
    "                          (batch, len(train_loader), np.mean(train_losses[-1]), np.mean(train_errors[-1])))\n",
    "                batch += 1\n",
    "                if callback is not None:\n",
    "                    callback()\n",
    "#                 except:\n",
    "#                     print(\"failed\")\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    Yval_pred = self.forward(Xval, evaluation=True)\n",
    "                    val_loss = self.loss(Yval, Yval_pred).item()\n",
    "                    val_losses.append(val_loss)\n",
    "                    val_error = 1-self.calc_accuracy(Yval, Yval_pred)\n",
    "                    val_errors.append(val_error)\n",
    "                    if val_error < best_val_error:\n",
    "                        consecutive_no_improvement = 0\n",
    "                        best_val_error = val_error\n",
    "                        info = \"training time in seconds: {}\\nepoch: {}\\nbatch size: {}\\ntrain slope: {}\\neval slope: {}\\nlearning rate: {}\\nvalidation loss: {}\\nvalidation error: {}\\n\".format(\n",
    "                        time.time()-total_time, epoch, batch_size, self.train_slope, self.eval_slope, opt_kwargs[\"lr\"], val_loss, val_error)\n",
    "                        self.save_model(train_errors, val_errors, train_losses, val_losses, info, path, comment)\n",
    "                        print(\"model saved!\")\n",
    "\n",
    "                    else:\n",
    "                        consecutive_no_improvement += 1\n",
    "                        if consecutive_no_improvement >= 4:\n",
    "                            break\n",
    "                except:\n",
    "                    print(\"failed\")\n",
    "                    \n",
    "            t2 = time.time()\n",
    "            if verbose:\n",
    "                print(\"------------- epoch %03d / %03d | time: %03d sec | loss: %3.5f | err: %3.5f\" % (epoch + 1, epochs, t2-t1, val_losses[-1], val_errors[-1]))\n",
    "        print(\"training time: {} seconds\".format(time.time()-total_time)) \n",
    "        return train_errors, val_errors, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " # PPO\n",
    " class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "class ValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super(ValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "class PPOClassifier(torch.nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim=128, action_dim=2, actor_lr=1e-3, critic_lr=1e-2, lmbda=0.95, epochs=10, eps=0.2, gamma=0.98, device=None):\n",
    "        super(PPOClassifier, self).__init__()\n",
    "        self.device = device if device is not None else (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "        self.actor = PolicyNet(x_dim, hidden_dim, action_dim).to(self.device)\n",
    "        self.critic = ValueNet(x_dim, hidden_dim).to(self.device)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=critic_lr)\n",
    "        self.gamma = gamma\n",
    "        self.lmbda = lmbda\n",
    "        self.epochs = epochs\n",
    "        self.eps = eps\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.to(self.device)\n",
    "        probs = self.actor(X)\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.forward(X)\n",
    "        return torch.argmax(probs, dim=1)*2-1  # output -1/1\n",
    "\n",
    "    def calc_accuracy(self, Y, Y_pred):\n",
    "        Y_pred = Y_pred.view(-1)\n",
    "        Y = Y.view(-1).to(y_pred.device)\n",
    "        acc = (Y_pred == Y).float().mean().item()\n",
    "        return acc\n",
    "\n",
    "    def fit(self, X, Y, Xval=None, Yval=None, batch_size=128, epochs=100, verbose=False):\n",
    "        dataset = TensorDataset(X, Y)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        best_val_acc = 0\n",
    "        for epoch in range(epochs):\n",
    "            batch_losses = []\n",
    "            batch_accs = []\n",
    "            for batch_idx, (Xbatch, Ybatch) in enumerate(loader):\n",
    "                Xbatch = Xbatch.to(self.device)\n",
    "                Ybatch = Ybatch.to(self.device)\n",
    "                # PPO update\n",
    "                probs = self.actor(Xbatch)\n",
    "                actions = torch.argmax(probs, dim=1)\n",
    "                # label: -1/1 -> 0/1\n",
    "                labels = ((Ybatch+1)//2).long().view(-1)\n",
    "                rewards = (actions == labels).float()\n",
    "                # 计算value和advantage\n",
    "                values = self.critic(Xbatch).squeeze(1)\n",
    "                td_target = rewards + self.gamma * values.detach()\n",
    "                td_delta = td_target - values\n",
    "                advantage = td_delta.detach()\n",
    "                old_log_probs = torch.log(probs.gather(1, actions.unsqueeze(1))).detach()\n",
    "                for _ in range(self.epochs):\n",
    "                    probs_new = self.actor(Xbatch)\n",
    "                    log_probs = torch.log(probs_new.gather(1, actions.unsqueeze(1)))\n",
    "                    ratio = torch.exp(log_probs - old_log_probs)\n",
    "                    surr1 = ratio * advantage.unsqueeze(1)\n",
    "                    surr2 = torch.clamp(ratio, 1 - self.eps, 1 + self.eps) * advantage.unsqueeze(1)\n",
    "                    actor_loss = -torch.mean(torch.min(surr1, surr2))\n",
    "                    critic_loss = torch.mean((self.critic(Xbatch).squeeze(1) - td_target.detach())**2)\n",
    "                    self.actor_optimizer.zero_grad()\n",
    "                    self.critic_optimizer.zero_grad()\n",
    "                    actor_loss.backward()\n",
    "                    critic_loss.backward()\n",
    "                    self.actor_optimizer.step()\n",
    "                    self.critic_optimizer.step()\n",
    "                # 记录loss和acc\n",
    "                batch_losses.append(actor_loss.item())\n",
    "                acc = (actions == labels).float().mean().item()\n",
    "                batch_accs.append(acc)\n",
    "                if verbose and ((batch_idx+1) % 5 == 0 or (batch_idx+1) == len(loader)):\n",
    "                    print(f\"batch {batch_idx+1:03d} / {len(loader):03d} | loss: {actor_loss.item():.5f} | acc: {acc:.5f}\")\n",
    "            # epoch结束，val acc\n",
    "            if Xval is not None and Yval is not None:\n",
    "                with torch.no_grad():\n",
    "                    Y_pred = self.predict(Xval.to(self.device))\n",
    "                    acc = self.calc_accuracy(Yval.to(self.device), Y_pred)\n",
    "                    if verbose:\n",
    "                        print(f\"------------- epoch {epoch+1:03d} / {epochs:03d} | loss: {np.mean(batch_losses):.5f} | acc: {np.mean(batch_accs):.5f} | val acc: {acc:.5f}\")\n",
    "                    if acc > best_val_acc:\n",
    "                        best_val_acc = acc\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"------------- epoch {epoch+1:03d} / {epochs:03d} | loss: {np.mean(batch_losses):.5f} | acc: {np.mean(batch_accs):.5f}\")\n",
    "        return best_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of positive samples: 52.77777777777778%\n"
     ]
    }
   ],
   "source": [
    "path = \"./models/robustness\"\n",
    "\n",
    "N = 300\n",
    "X, Y = gen_custom_normal_data(N, torch.Tensor([0.6, 0]), torch.Tensor([0.1, 0.1]), torch.Tensor([-0.6, 0]), torch.Tensor([0.1, 0.1]))\n",
    "\n",
    "assert(len(X[0]) == XDIM)\n",
    "X, Y, Xval, Yval = split_data(X, Y, 0.4)\n",
    "Xval, Yval, Xtest, Ytest = split_data(Xval, Yval, 0.5)\n",
    "\n",
    "print(\"percent of positive samples: {}%\".format(100 * len(Y[Y == 1]) / len(Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 6\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "x_dim = XDIM\n",
    "v_true = torch.Tensor([0.5, 0.5])\n",
    "v_0 = torch.Tensor([2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 008 / 012 | loss: 0.62601 | err: 0.46875\n",
      "batch 009 / 012 | loss: 0.62106 | err: 0.46528\n",
      "batch 010 / 012 | loss: 0.63394 | err: 0.47500\n",
      "batch 011 / 012 | loss: 0.62314 | err: 0.45455\n",
      "batch 012 / 012 | loss: 0.60543 | err: 0.41667\n",
      "model saved!\n",
      "------------- epoch 003 / 006 | time: 007 sec | loss: 0.21258 | err: 0.00000\n",
      "batch 001 / 012 | loss: 0.46805 | err: 0.00000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# non-strategic classification\n",
    "print(\"---------- training non-strategically----------\")\n",
    "non_strategic_model = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, v_0, v_true, strategic=False, robust=False)\n",
    "\n",
    "non_strategic_model.fit(path, X, Y, Xval, Yval,\n",
    "                                opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-1)},\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True, \n",
    "                                comment=\"non_strategic\")\n",
    "\n",
    "# strategic classification, fixed\n",
    "print(\"---------- training strategically----------\")\n",
    "strategic_model_oracle = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, v_true, v_true, strategic=True, robust=False)\n",
    "\n",
    "strategic_model_oracle.fit(path, X, Y, Xval, Yval,\n",
    "                                opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-1)},\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True,\n",
    "                                comment=\"oracle\")\n",
    "\n",
    "# strategic classification, flexible\n",
    "print(\"---------- training strategically----------\")\n",
    "strategic_model_robust = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, v_0, v_true, strategic=True, robust=True)\n",
    "\n",
    "strategic_model_robust.fit(path, X, Y, Xval, Yval,\n",
    "                                opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-1)},\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True,\n",
    "                                comment=\"robust\")\n",
    "\n",
    "# strategic classification, fixed\n",
    "print(\"---------- training strategically----------\")\n",
    "strategic_model_fragile = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, v_0, v_true, strategic=True, robust=False)\n",
    "\n",
    "strategic_model_fragile.fit(path, X, Y, Xval, Yval,\n",
    "                                opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-1)},\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True,\n",
    "                                comment=\"fragile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- training with PPOClassifier ----------\n",
      "batch 005 / 012 | loss: -0.64054 | acc: 0.68750\n",
      "batch 010 / 012 | loss: -0.48477 | acc: 0.62500\n",
      "batch 012 / 012 | loss: -0.34240 | acc: 0.50000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------- training with PPOClassifier ----------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m ppo_model \u001b[38;5;241m=\u001b[39m PPOClassifier(x_dim, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, action_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, actor_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, critic_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, epochs\u001b[38;5;241m=\u001b[39mEPOCHS, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.98\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mppo_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# acc_val\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[0;32mIn[26], line 95\u001b[0m, in \u001b[0;36mPPOClassifier.fit\u001b[0;34m(self, X, Y, Xval, Yval, batch_size, epochs, verbose)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     94\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(Xval\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m---> 95\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------- epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(batch_losses)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(batch_accs)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | val acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 45\u001b[0m, in \u001b[0;36mPPOClassifier.calc_accuracy\u001b[0;34m(self, Y, Y_pred)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalc_accuracy\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, Y_pred):\n\u001b[1;32m     44\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m Y_pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[43my_pred\u001b[49m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     46\u001b[0m     acc \u001b[38;5;241m=\u001b[39m (Y_pred \u001b[38;5;241m==\u001b[39m Y)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acc\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"---------- training with PPOClassifier ----------\")\n",
    "ppo_model = PPOClassifier(x_dim, hidden_dim=128, action_dim=2, actor_lr=1e-3, critic_lr=1e-2, epochs=EPOCHS, gamma=0.98)\n",
    "ppo_model.fit(X, Y, Xval, Yval, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True)\n",
    "\n",
    "# acc_val\n",
    "with torch.no_grad():\n",
    "    Y_pred = ppo_model.predict(Xval)\n",
    "    acc = ppo_model.calc_accuracy(Yval, Y_pred)\n",
    "    print(f\"PPOClassifier val acc: {acc:.4f}\")\n",
    "\n",
    "# acc_text  \n",
    "with torch.no_grad():\n",
    "    Y_pred_test = ppo_model.predict(Xtest)\n",
    "    acc_test = ppo_model.calc_accuracy(Ytest, Y_pred_test)\n",
    "    print(f\"PPOClassifier test acc: {acc_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madePractical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
